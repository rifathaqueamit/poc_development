{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rifathaqueamit/poc_development/blob/develop/poc_v_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Demonstration of the POC for searching content inside video</h1>"
      ],
      "metadata": {
        "id": "Had2ogKlkiJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prerequisites\n",
        "\n",
        "Go through steps one by one\n",
        "\n",
        "Update : V12 (24th Oct, 2023)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1-wWKf8hmmqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3khsunT7kWa",
        "outputId": "beec817d-5418-44ae-9b2a-25433a07ac92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title 1. Install dependencies\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI_1csl6Q-gH"
      },
      "outputs": [],
      "source": [
        "# @title 2. Import dependencies\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapy as media\n",
        "import numpy as np\n",
        "import PIL\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import tqdm\n",
        "import absl.logging\n",
        "import random\n",
        "import re\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import imageio\n",
        "import requests\n",
        "import json\n",
        "import glob\n",
        "\n",
        "from IPython import display\n",
        "from urllib import request\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "mpl.rcParams.update({\n",
        "    'font.size': 10,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Define constants (if required)\n",
        "#Common constants\n",
        "input_videos_path = \"input_videos\"\n",
        "output_videos_path = \"output_videos\"\n",
        "video_fps = 5\n",
        "seconds_per_segments = 5 #5/10/15\n",
        "threshold = 50\n",
        "frames_per_video = seconds_per_segments * video_fps\n",
        "\n",
        "#Action detection\n",
        "action_frame_width = 224\n",
        "action_frame_height = 224\n",
        "\n",
        "#Object detection\n",
        "object_frame_width = 320\n",
        "object_frame_height = 320\n",
        "class_names = [\n",
        "      \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\",\n",
        "      \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\",\n",
        "      \"fire hydrant\", \"---\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "      \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
        "      \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"---\", \"backpack\",\n",
        "      \"umbrella\", \"---\", \"---\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
        "      \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "      \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
        "      \"bottle\", \"---\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\",\n",
        "      \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
        "      \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
        "      \"couch\", \"potted plant\", \"bed\", \"---\",  \"dining table\", \"---\", \"---\",\n",
        "      \"toilet\", \"---\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "      \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"---\", \"book\",\n",
        "      \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\", \"---\"\n",
        "  ]"
      ],
      "metadata": {
        "id": "nFMSuU4aoXIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Get necessary files\n",
        "\n",
        "#Create folders\n",
        "if os.path.exists(input_videos_path) == False:\n",
        "  os.mkdir(input_videos_path)\n",
        "\n",
        "if os.path.exists(output_videos_path) == False:\n",
        "  os.mkdir(output_videos_path)\n",
        "\n",
        "# Clean folders\n",
        "files = glob.glob('/content/' + input_videos_path + '/*')\n",
        "for f in files:\n",
        "  os.remove(f)\n",
        "\n",
        "files = glob.glob('/content/' + output_videos_path + '/*')\n",
        "for f in files:\n",
        "  os.remove(f)\n",
        "\n",
        "# Load models\n",
        "if os.path.exists(\"/content/action_model.tflite\") == False:\n",
        "  !wget https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/action_model.tflite\n",
        "\n",
        "if os.path.exists(\"/content/object_model.tflite\") == False:\n",
        "  !wget https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/object_model.tflite\n",
        "\n",
        "# Load input videos\n",
        "res = requests.get('https://github.com/rifathaqueamit/poc_development/tree/develop/input_videos')\n",
        "data = json.loads(res.text)\n",
        "files = data['payload']['tree']['items']\n",
        "\n",
        "for file_item in files:\n",
        "  name = file_item['name']\n",
        "  path = \"https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/input_videos/\" + name\n",
        "  path = path.replace(\" \", \"%20\")\n",
        "  !wget $path\n",
        "  os.rename(\"/content/\" + name, '/content/' + input_videos_path + '/' + name)\n",
        "  print(\"Loaded : \", name)\n"
      ],
      "metadata": {
        "id": "upRlRCpF14Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx55NK3ZoZeh"
      },
      "outputs": [],
      "source": [
        "# @title 5. Helper functions\n",
        "\n",
        "# Download Kinetics 600 label map\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt -O labels.txt -q\n",
        "\n",
        "with tf.io.gfile.GFile('labels.txt') as f:\n",
        "  lines = f.readlines()\n",
        "  KINETICS_600_LABELS_LIST = [line.strip() for line in lines]\n",
        "  KINETICS_600_LABELS = tf.constant(KINETICS_600_LABELS_LIST)\n",
        "\n",
        "def get_top_k(probs, k=5, label_map=KINETICS_600_LABELS):\n",
        "  \"\"\"Outputs the top k model labels and probabilities on the given video.\"\"\"\n",
        "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
        "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
        "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
        "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
        "  return tuple(zip(top_labels, top_probs))\n",
        "\n",
        "# Utilities to open video files using CV2\n",
        "def crop_center_square(frame):\n",
        "  y, x = frame.shape[0:2]\n",
        "  min_dim = min(y, x)\n",
        "  start_x = (x // 2) - (min_dim // 2)\n",
        "  start_y = (y // 2) - (min_dim // 2)\n",
        "  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(object_frame_width, object_frame_height)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      frame = crop_center_square(frame)\n",
        "      frame = cv2.resize(frame, resize)\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "\n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Load pre-trained model\n",
        "# Create the interpreter and signature runner\n",
        "action_interpreter = tf.lite.Interpreter(model_path=\"action_model.tflite\")\n",
        "action_runner = action_interpreter.get_signature_runner()\n",
        "\n",
        "object_interpreter = tf.lite.Interpreter(model_path=\"object_model.tflite\")\n",
        "object_interpreter.allocate_tensors()"
      ],
      "metadata": {
        "id": "LlfrEvXvZFEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Collect input videos (Mp4 only)\n",
        "input_videos = []\n",
        "\n",
        "for file in os.listdir(\"input_videos\"):\n",
        "    if file.endswith(\".mp4\"):\n",
        "        input_videos.append(file)\n",
        "\n",
        "if len(input_videos) == 0:\n",
        "  print(\"There is no input videos\")\n",
        "else:\n",
        "  print(input_videos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY4FGs4xwnmU",
        "outputId": "71a5ff01-1dae-447c-b31f-e28da120e7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['video9.mp4', 'video2.mp4', 'video12.mp4', 'video8.mp4', 'video14.mp4', 'video17.mp4', 'video16.mp4', 'video6.mp4', 'video4.mp4', 'video15.mp4', 'video3.mp4', 'video11.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 8. Convert the input mp4 video into AVI format\n",
        "output_videos = []\n",
        "for input_video in input_videos:\n",
        "  input_path = input_videos_path + \"/\" + input_video\n",
        "  path, filename_ext = os.path.split(input_path)\n",
        "  filename = os.path.splitext(filename_ext)\n",
        "  output_path = output_videos_path + \"/\" + filename[0] + \".avi\"\n",
        "  if os.path.exists(output_path):\n",
        "    os.remove(output_path)\n",
        "  print(\"Input : \", input_path)\n",
        "  print(\"Output : \", output_path)\n",
        "  !ffmpeg -i $input_path -filter:v fps=$video_fps $output_path\n",
        "  output_videos.append(output_path)"
      ],
      "metadata": {
        "id": "oCHpfTsljZJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Load the videos\n",
        "action_videos = []\n",
        "object_videos = []\n",
        "for url in output_videos:\n",
        "  object_video = load_video(url)\n",
        "  action_video = load_video(url, resize=(action_frame_width, action_frame_height)) / 255\n",
        "  # media.show_video(loaded_video, fps=video_fps)\n",
        "\n",
        "  print(\"path : \", url)\n",
        "  print(\"action video frames count, width, height, color : \", action_video.shape)\n",
        "  print(\"object video frames count, width, height, color : \", object_video.shape)\n",
        "\n",
        "  action_videos.append((url, action_video))\n",
        "  object_videos.append((url, object_video))"
      ],
      "metadata": {
        "id": "KBh2njQJaCZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10. Separate the videos in small segments\n",
        "def separateVideoInSegments(url, video_frames):\n",
        "  print(\"separateVideoInSegments() : \", url)\n",
        "  video_segments = []\n",
        "  video_segments_playable = []\n",
        "\n",
        "  for idx, frame in enumerate(video_frames):\n",
        "    video_id = int(idx / frames_per_video)\n",
        "    try:\n",
        "      f32_frame = tf.cast(frame, tf.float32)\n",
        "      video_segments[video_id].append(f32_frame)\n",
        "      video_segments_playable[video_id].append(frame)\n",
        "    except IndexError:\n",
        "      video_segments.append([f32_frame])\n",
        "      video_segments_playable.append([frame])\n",
        "\n",
        "  for idx, segment in enumerate(video_segments):\n",
        "    print(\"Segment \", idx+1, \", total frames : \", len(segment))\n",
        "\n",
        "  return (url, video_segments, video_segments_playable)"
      ],
      "metadata": {
        "id": "uhE11gzJJui5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_videos_segments = []\n",
        "object_videos_segments = []\n",
        "video_segments_detection = {}\n",
        "object_segments_detection = {}\n",
        "\n",
        "# Action videos\n",
        "for url, video in action_videos:\n",
        "  action_videos_segments.append(separateVideoInSegments(url, video))\n",
        "\n",
        "for url, video in object_videos:\n",
        "  object_videos_segments.append(separateVideoInSegments(url, video))\n",
        "\n",
        "for url, video in action_videos:\n",
        "  video_segments_detection[url] = []\n",
        "  object_segments_detection[url] = []"
      ],
      "metadata": {
        "id": "EVSq6Ler0nIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 11. Define the detect function for video classification\n",
        "def detectFirstPrint(video):\n",
        "  init_states = {\n",
        "    name: tf.zeros(x['shape'], dtype=x['dtype'])\n",
        "    for name, x in action_runner.get_input_details().items()\n",
        "  }\n",
        "  del init_states['image']\n",
        "\n",
        "  clips = video\n",
        "  states = init_states\n",
        "  for clip in clips:\n",
        "    # Input shape: [1, 1, 224, 224, 3]\n",
        "    outputs = action_runner(**states, image=clip)\n",
        "    logits = outputs.pop('logits')[0]\n",
        "    states = outputs\n",
        "\n",
        "  probs = tf.nn.softmax(logits)\n",
        "  top_k = get_top_k(probs)\n",
        "\n",
        "  for label, prob in top_k:\n",
        "    if prob * 100 >= threshold:\n",
        "      print(\"     Action : \" + label + \", with probability : \" + str(prob * 100) + \"%\")\n",
        "      video_segments_detection[url].append(label)\n",
        "      return\n",
        "\n",
        "  print(\"     Action : nothing detected\")\n",
        "  video_segments_detection[url].append(\"nothing\")"
      ],
      "metadata": {
        "id": "NRxJJ-ZeXNtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 12. Run inference for video classification\n",
        "\n",
        "# Video action classification\n",
        "for video in action_videos_segments:\n",
        "  url = video[0]\n",
        "  video_segments = video[1]\n",
        "  video_segments_playable = video[2]\n",
        "\n",
        "  video_segments_detection[url].clear()\n",
        "\n",
        "  print(\"Url : \", url)\n",
        "  print(\".............................\")\n",
        "\n",
        "  segment_id = 0\n",
        "  for segment in video_segments:\n",
        "    segment_start_time = segment_id * seconds_per_segments\n",
        "    segment_end_time = (segment_id + 1) * seconds_per_segments\n",
        "    print(\"Segment : \", segment_id+1, \" , start : \", segment_start_time, \" , end : \", segment_end_time)\n",
        "    detectFirstPrint(video_segments[segment_id])\n",
        "    # media.show_video(video_segments_playable[segment_id], fps=video_fps)\n",
        "    segment_id = segment_id + 1"
      ],
      "metadata": {
        "id": "KTAZfYF05wd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 13. Prepare details for object interpreter\n",
        "object_input_details = object_interpreter.get_input_details()\n",
        "object_output_details = object_interpreter.get_output_details()\n",
        "object_input_shape = object_input_details[0]['shape'][1:3]"
      ],
      "metadata": {
        "id": "UxNPc22s5dGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 14. Define object detection function\n",
        "def detectObjects(segmentId, video):\n",
        "  all_detections = set()\n",
        "  for idx, frame in enumerate(video):\n",
        "    if idx % video_fps == 0:\n",
        "      # detected_objects_in_frame = []\n",
        "      #plt.imshow(frame / 255)\n",
        "      #plt.axis('off')\n",
        "      #plt.show()\n",
        "      int_frame = np.array(frame, dtype=np.uint8)\n",
        "      int_frame = np.expand_dims(int_frame, axis=0)\n",
        "      object_interpreter.set_tensor(object_input_details[0]['index'], int_frame)\n",
        "      object_interpreter.invoke()\n",
        "      classes = object_interpreter.get_tensor(object_output_details[1]['index'])\n",
        "      scores = object_interpreter.get_tensor(object_output_details[2]['index'])\n",
        "      num_detections = int(object_interpreter.get_tensor(object_output_details[3]['index']))\n",
        "\n",
        "      detections = set()\n",
        "\n",
        "      for k in range(num_detections):\n",
        "        if scores[0, k] > (threshold / float(100)):\n",
        "            class_id = int(classes[0, k])\n",
        "            class_name = class_names[class_id]\n",
        "            # confidence = scores[0, k]\n",
        "            # label = f\"class name = {class_name}, class id = {class_id + 1}, confidence = {confidence:.2f}\"\n",
        "            # print(label)\n",
        "            # detected_objects_in_frame.append(label)\n",
        "            detections.add(class_name)\n",
        "      # print(\"     Frame : \", idx, \", Detections : \", detections)\n",
        "      for item in detections:\n",
        "        all_detections.add(item)\n",
        "  print(\"Segment detections : \", all_detections)\n",
        "  return all_detections"
      ],
      "metadata": {
        "id": "G73-rB6q24K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 15. Run inference for object detection\n",
        "for video in object_videos_segments:\n",
        "  url = video[0]\n",
        "  video_segments = video[1]\n",
        "  video_segments_playable = video[2]\n",
        "\n",
        "  object_segments_detection[url].clear()\n",
        "\n",
        "  print(\"Url : \", url)\n",
        "  print(\".............................\")\n",
        "\n",
        "  segment_id = 0\n",
        "  for segment in video_segments:\n",
        "    segment_start_time = segment_id * seconds_per_segments\n",
        "    segment_end_time = (segment_id + 1) * seconds_per_segments\n",
        "    print(\"Segment : \", segment_id+1, \" , start : \", segment_start_time, \" , end : \", segment_end_time)\n",
        "    detections = detectObjects(segment_id, video_segments[segment_id])\n",
        "    object_segments_detection[url].append(detections)\n",
        "    # media.show_video(video_segments_playable[segment_id], fps=video_fps)\n",
        "    segment_id = segment_id + 1"
      ],
      "metadata": {
        "id": "0MFD6ZIG2lRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 16. Collect everything together\n",
        "individual_segment_wise_detections = []\n",
        "video_segment_detections = {}\n",
        "\n",
        "for url, video in action_videos:\n",
        "  video_segment_detections[url] = []\n",
        "\n",
        "for url, detections in video_segments_detection.items():\n",
        "  print(detections)\n",
        "  individual_segment_wise_detections.clear()\n",
        "  segment_id = 0\n",
        "  for dect in detections:\n",
        "    if dect != \"nothing\":\n",
        "      individual_segment_wise_detections.append({dect})\n",
        "    else:\n",
        "      individual_segment_wise_detections.append(set())\n",
        "    for setItem in object_segments_detection[url][segment_id]:\n",
        "      individual_segment_wise_detections[len(individual_segment_wise_detections) - 1].add(setItem)\n",
        "    segment_id = segment_id + 1\n",
        "  video_segment_detections[url] = individual_segment_wise_detections.copy()\n",
        "\n",
        "print(\"Videos detections : \")\n",
        "print(video_segment_detections)"
      ],
      "metadata": {
        "id": "WmjgxYYY46ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 17. Some more utilities\n",
        "def searchAtleastOneTerm(terms, text):\n",
        "  for term in terms:\n",
        "    if term in text:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def searchAllTerms(terms, text):\n",
        "  found_terms = 0\n",
        "  for term in terms:\n",
        "    if term in text:\n",
        "      found_terms = found_terms + 1\n",
        "  if found_terms == len(terms):\n",
        "    print(found_terms)\n",
        "    return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "nAU_ysX2MTuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 18. Demonstration by video\n",
        "search = \"punching bag cooking and playing soccer\" # @param {type:\"string\"}\n",
        "search_terms = search.lower().split()\n",
        "\n",
        "if len(search_terms) > 0:\n",
        "  found_videos = []\n",
        "  for url, detections in video_segment_detections.items():\n",
        "    for segment in detections:\n",
        "      for item in segment:\n",
        "        if searchAtleastOneTerm(search_terms, item):\n",
        "          found_videos.append(url)\n",
        "      else:\n",
        "        continue\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "    break\n",
        "  for url, video in object_videos:\n",
        "    for item in found_videos:\n",
        "      if url == item:\n",
        "        media.show_video(video, fps=video_fps)\n",
        "        break"
      ],
      "metadata": {
        "id": "5lVkIJyr4-HW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}