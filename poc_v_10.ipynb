{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rifathaqueamit/poc_development/blob/develop/poc_v_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Demonstration of the POC for searching content inside video</h1>"
      ],
      "metadata": {
        "id": "Had2ogKlkiJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prerequisites\n",
        "\n",
        "\n",
        "1.  Create a folder with name \"input_videos\" and put your video files as mp4\n",
        "2.  Upload the action_model.tflite file\n",
        "3.  Upload the object_model.tflite file\n",
        "4.  Go through steps one by one\n",
        "\n",
        "Update : V8 (19th Oct, 2023)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1-wWKf8hmmqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s3khsunT7kWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a688d0bc-8e5b-41c6-be52-03d3f5bc0829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.6 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.5/1.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title 1. Install dependencies\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dI_1csl6Q-gH"
      },
      "outputs": [],
      "source": [
        "# @title 2. Import dependencies\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapy as media\n",
        "import numpy as np\n",
        "import PIL\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import tqdm\n",
        "import absl.logging\n",
        "import random\n",
        "import re\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import imageio\n",
        "from IPython import display\n",
        "from urllib import request\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "mpl.rcParams.update({\n",
        "    'font.size': 10,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Define constants (if required)\n",
        "#Common constants\n",
        "input_videos_path = \"input_videos\"\n",
        "output_videos_path = \"output_videos\"\n",
        "video_fps = 5\n",
        "seconds_per_segments = 5\n",
        "threshold = 50\n",
        "frames_per_video = seconds_per_segments * video_fps\n",
        "\n",
        "#Action detection\n",
        "action_frame_width = 224\n",
        "action_frame_height = 224\n",
        "\n",
        "#Object detection\n",
        "object_frame_width = 320\n",
        "object_frame_height = 320\n",
        "class_names = [\n",
        "      \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\",\n",
        "      \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\",\n",
        "      \"fire hydrant\", \"---\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "      \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
        "      \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"---\", \"backpack\",\n",
        "      \"umbrella\", \"---\", \"---\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
        "      \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "      \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
        "      \"bottle\", \"---\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\",\n",
        "      \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
        "      \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
        "      \"couch\", \"potted plant\", \"bed\", \"---\",  \"dining table\", \"---\", \"---\",\n",
        "      \"toilet\", \"---\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "      \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"---\", \"book\",\n",
        "      \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\", \"---\"\n",
        "  ]"
      ],
      "metadata": {
        "id": "nFMSuU4aoXIx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Get necessary files\n",
        "if os.path.exists(input_videos_path) == False:\n",
        "  os.mkdir(input_videos_path)\n",
        "\n",
        "if os.path.exists(output_videos_path) == False:\n",
        "  os.mkdir(output_videos_path)\n",
        "\n",
        "if os.path.exists(\"/content/action_model.tflite\") == False:\n",
        "  !wget https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/action_model.tflite\n",
        "\n",
        "if os.path.exists(\"/content/object_model.tflite\") == False:\n",
        "  !wget https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/object_model.tflite\n",
        "\n",
        "if os.path.exists(\"/content/input_videos/video1.mp4\") == False:\n",
        "  !wget https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/video1.mp4\n",
        "  os.rename(\"/content/video1.mp4\", \"/content/input_videos/video1.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upRlRCpF14Em",
        "outputId": "92a52c0e-a2ea-444d-fd36-51614b9b02a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-22 05:35:05--  https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/action_model.tflite\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16088600 (15M) [application/octet-stream]\n",
            "Saving to: ‘action_model.tflite’\n",
            "\n",
            "action_model.tflite 100%[===================>]  15.34M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-22 05:35:06 (283 MB/s) - ‘action_model.tflite’ saved [16088600/16088600]\n",
            "\n",
            "--2023-10-22 05:35:06--  https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/object_model.tflite\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4563519 (4.4M) [application/octet-stream]\n",
            "Saving to: ‘object_model.tflite’\n",
            "\n",
            "object_model.tflite 100%[===================>]   4.35M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-22 05:35:07 (94.1 MB/s) - ‘object_model.tflite’ saved [4563519/4563519]\n",
            "\n",
            "--2023-10-22 05:35:07--  https://raw.githubusercontent.com/rifathaqueamit/poc_development/develop/video1.mp4\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2442131 (2.3M) [application/octet-stream]\n",
            "Saving to: ‘video1.mp4’\n",
            "\n",
            "video1.mp4          100%[===================>]   2.33M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-10-22 05:35:07 (92.8 MB/s) - ‘video1.mp4’ saved [2442131/2442131]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dx55NK3ZoZeh"
      },
      "outputs": [],
      "source": [
        "# @title 5. Helper functions\n",
        "\n",
        "# Download Kinetics 600 label map\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt -O labels.txt -q\n",
        "\n",
        "with tf.io.gfile.GFile('labels.txt') as f:\n",
        "  lines = f.readlines()\n",
        "  KINETICS_600_LABELS_LIST = [line.strip() for line in lines]\n",
        "  KINETICS_600_LABELS = tf.constant(KINETICS_600_LABELS_LIST)\n",
        "\n",
        "def get_top_k(probs, k=5, label_map=KINETICS_600_LABELS):\n",
        "  \"\"\"Outputs the top k model labels and probabilities on the given video.\"\"\"\n",
        "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
        "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
        "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
        "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
        "  return tuple(zip(top_labels, top_probs))\n",
        "\n",
        "# Utilities to open video files using CV2\n",
        "def crop_center_square(frame):\n",
        "  y, x = frame.shape[0:2]\n",
        "  min_dim = min(y, x)\n",
        "  start_x = (x // 2) - (min_dim // 2)\n",
        "  start_y = (y // 2) - (min_dim // 2)\n",
        "  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(object_frame_width, object_frame_height)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      frame = crop_center_square(frame)\n",
        "      frame = cv2.resize(frame, resize)\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "\n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Load pre-trained model\n",
        "# Create the interpreter and signature runner\n",
        "action_interpreter = tf.lite.Interpreter(model_path=\"action_model.tflite\")\n",
        "action_runner = action_interpreter.get_signature_runner()\n",
        "\n",
        "object_interpreter = tf.lite.Interpreter(model_path=\"object_model.tflite\")\n",
        "object_interpreter.allocate_tensors()"
      ],
      "metadata": {
        "id": "LlfrEvXvZFEV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Collect input videos (Mp4 only)\n",
        "input_videos = []\n",
        "\n",
        "for file in os.listdir(\"input_videos\"):\n",
        "    if file.endswith(\".mp4\"):\n",
        "        input_videos.append(file)\n",
        "\n",
        "if len(input_videos) == 0:\n",
        "  print(\"There is no input videos\")\n",
        "else:\n",
        "  print(input_videos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY4FGs4xwnmU",
        "outputId": "94df99f9-7646-42b8-b439-b61b53a70062"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['video1.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 8. Convert the input mp4 video into AVI format\n",
        "output_videos = []\n",
        "for input_video in input_videos:\n",
        "  input_path = input_videos_path + \"/\" + input_video\n",
        "  path, filename_ext = os.path.split(input_path)\n",
        "  filename = os.path.splitext(filename_ext)\n",
        "  output_path = output_videos_path + \"/\" + filename[0] + \".avi\"\n",
        "  if os.path.exists(output_path):\n",
        "    os.remove(output_path)\n",
        "  print(\"Input : \", input_path)\n",
        "  print(\"Output : \", output_path)\n",
        "  !ffmpeg -i $input_path -filter:v fps=$video_fps $output_path\n",
        "  output_videos.append(output_path)"
      ],
      "metadata": {
        "id": "oCHpfTsljZJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd207bb4-ab60-4579-89c3-fde7e2eca304"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input :  input_videos/video1.mp4\n",
            "Output :  output_videos/video1.avi\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_videos/video1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf59.27.100\n",
            "  Duration: 00:00:15.30, start: 0.000000, bitrate: 1276 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, smpte170m/bt470bg/smpte170m), 640x368 [SAR 1:1 DAR 40:23], 1202 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc59.37.100 libx264\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 64 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mpeg4 (native))\n",
            "  Stream #0:1 -> #0:1 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, avi, to 'output_videos/video1.avi':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: mpeg4 (FMP4 / 0x34504D46), yuv420p(tv, smpte170m/bt470bg/smpte170m, progressive), 640x368 [SAR 1:1 DAR 40:23], q=2-31, 200 kb/s, 5 fps, 5 tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 mpeg4\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1(und): Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "frame=   77 fps= 46 q=21.2 Lsize=     791kB time=00:00:15.40 bitrate= 420.7kbits/s speed=9.25x    \n",
            "video:525kB audio:240kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.482016%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Load the videos and show\n",
        "action_videos = []\n",
        "object_videos = []\n",
        "for url in output_videos:\n",
        "  object_video = load_video(url)\n",
        "  action_video = load_video(url, resize=(action_frame_width, action_frame_height)) / 255\n",
        "  # media.show_video(loaded_video, fps=video_fps)\n",
        "\n",
        "  print(\"path : \", url)\n",
        "  print(\"action video frames count, width, height, color : \", action_video.shape)\n",
        "  print(\"object video frames count, width, height, color : \", object_video.shape)\n",
        "\n",
        "  action_videos.append((url, action_video))\n",
        "  object_videos.append((url, object_video))"
      ],
      "metadata": {
        "id": "KBh2njQJaCZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6caa45-f5da-4b79-c17c-11e2f6c4dd23"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "path :  output_videos/video1.avi\n",
            "action video frames count, width, height, color :  (77, 224, 224, 3)\n",
            "object video frames count, width, height, color :  (77, 320, 320, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10. Separate the videos in small segments\n",
        "def separateVideoInSegments(url, video_frames):\n",
        "  print(\"separateVideoInSegments() : \", url)\n",
        "  video_segments = []\n",
        "  video_segments_playable = []\n",
        "\n",
        "  for idx, frame in enumerate(video_frames):\n",
        "    video_id = int(idx / frames_per_video)\n",
        "    try:\n",
        "      f32_frame = tf.cast(frame, tf.float32)\n",
        "      video_segments[video_id].append(f32_frame)\n",
        "      video_segments_playable[video_id].append(frame)\n",
        "    except IndexError:\n",
        "      video_segments.append([f32_frame])\n",
        "      video_segments_playable.append([frame])\n",
        "\n",
        "  for idx, segment in enumerate(video_segments):\n",
        "    print(\"Segment \", idx+1, \", total frames : \", len(segment))\n",
        "\n",
        "  return (url, video_segments, video_segments_playable)"
      ],
      "metadata": {
        "id": "uhE11gzJJui5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_videos_segments = []\n",
        "object_videos_segments = []\n",
        "video_segments_detection = {}\n",
        "object_segments_detection = {}\n",
        "\n",
        "# Action videos\n",
        "for url, video in action_videos:\n",
        "  action_videos_segments.append(separateVideoInSegments(url, video))\n",
        "\n",
        "for url, video in object_videos:\n",
        "  object_videos_segments.append(separateVideoInSegments(url, video))\n",
        "\n",
        "for url, video in action_videos:\n",
        "  video_segments_detection[url] = []\n",
        "  object_segments_detection[url] = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVSq6Ler0nIJ",
        "outputId": "ff12648d-bf7b-41f0-9ed6-09b71c2dc5dd"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "separateVideoInSegments() :  output_videos/video1.avi\n",
            "Segment  1 , total frames :  25\n",
            "Segment  2 , total frames :  25\n",
            "Segment  3 , total frames :  25\n",
            "Segment  4 , total frames :  2\n",
            "separateVideoInSegments() :  output_videos/video1.avi\n",
            "Segment  1 , total frames :  25\n",
            "Segment  2 , total frames :  25\n",
            "Segment  3 , total frames :  25\n",
            "Segment  4 , total frames :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 11. Define the detect function for video classification\n",
        "def detectFirstPrint(video):\n",
        "  init_states = {\n",
        "    name: tf.zeros(x['shape'], dtype=x['dtype'])\n",
        "    for name, x in action_runner.get_input_details().items()\n",
        "  }\n",
        "  del init_states['image']\n",
        "\n",
        "  clips = video\n",
        "  states = init_states\n",
        "  for clip in clips:\n",
        "    # Input shape: [1, 1, 224, 224, 3]\n",
        "    outputs = action_runner(**states, image=clip)\n",
        "    logits = outputs.pop('logits')[0]\n",
        "    states = outputs\n",
        "\n",
        "  probs = tf.nn.softmax(logits)\n",
        "  top_k = get_top_k(probs)\n",
        "\n",
        "  for label, prob in top_k:\n",
        "    if prob * 100 >= threshold:\n",
        "      print(\"     Action : \" + label + \", with probability : \" + str(prob * 100) + \"%\")\n",
        "      video_segments_detection[url].append(label)\n",
        "      return\n",
        "\n",
        "  print(\"     Action : nothing detected\")\n",
        "  video_segments_detection[url].append(\"nothing\")"
      ],
      "metadata": {
        "id": "NRxJJ-ZeXNtd"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 12. Run inference for video classification\n",
        "\n",
        "# Video action classification\n",
        "for video in action_videos_segments:\n",
        "  url = video[0]\n",
        "  video_segments = video[1]\n",
        "  video_segments_playable = video[2]\n",
        "\n",
        "  video_segments_detection[url].clear()\n",
        "\n",
        "  print(\"Url : \", url)\n",
        "  print(\".............................\")\n",
        "\n",
        "  segment_id = 0\n",
        "  for segment in video_segments:\n",
        "    segment_start_time = segment_id * seconds_per_segments\n",
        "    segment_end_time = (segment_id + 1) * seconds_per_segments\n",
        "    print(\"Segment : \", segment_id+1, \" , start : \", segment_start_time, \" , end : \", segment_end_time)\n",
        "    detectFirstPrint(video_segments[segment_id])\n",
        "    # media.show_video(video_segments_playable[segment_id], fps=video_fps)\n",
        "    segment_id = segment_id + 1"
      ],
      "metadata": {
        "id": "KTAZfYF05wd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615e4204-3577-4a82-deb6-8bb333127901"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Url :  output_videos/video1.avi\n",
            ".............................\n",
            "Segment :  1  , start :  0  , end :  5\n",
            "     Action : salsa dancing, with probability : 97.83188700675964%\n",
            "Segment :  2  , start :  5  , end :  10\n",
            "     Action : salsa dancing, with probability : 88.37749361991882%\n",
            "Segment :  3  , start :  10  , end :  15\n",
            "     Action : nothing detected\n",
            "Segment :  4  , start :  15  , end :  20\n",
            "     Action : nothing detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 13. Prepare details for object interpreter\n",
        "object_input_details = object_interpreter.get_input_details()\n",
        "object_output_details = object_interpreter.get_output_details()\n",
        "object_input_shape = object_input_details[0]['shape'][1:3]"
      ],
      "metadata": {
        "id": "UxNPc22s5dGC"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 14. Define object detection function\n",
        "def detectObjects(segmentId, video):\n",
        "  all_detections = set()\n",
        "  for idx, frame in enumerate(video):\n",
        "    if idx % video_fps == 0:\n",
        "      # detected_objects_in_frame = []\n",
        "      #plt.imshow(frame / 255)\n",
        "      #plt.axis('off')\n",
        "      #plt.show()\n",
        "      int_frame = np.array(frame, dtype=np.uint8)\n",
        "      int_frame = np.expand_dims(int_frame, axis=0)\n",
        "      object_interpreter.set_tensor(object_input_details[0]['index'], int_frame)\n",
        "      object_interpreter.invoke()\n",
        "      classes = object_interpreter.get_tensor(object_output_details[1]['index'])\n",
        "      scores = object_interpreter.get_tensor(object_output_details[2]['index'])\n",
        "      num_detections = int(object_interpreter.get_tensor(object_output_details[3]['index']))\n",
        "\n",
        "      detections = set()\n",
        "\n",
        "      for k in range(num_detections):\n",
        "        if scores[0, k] > (threshold / float(100)):\n",
        "            class_id = int(classes[0, k])\n",
        "            class_name = class_names[class_id]\n",
        "            # confidence = scores[0, k]\n",
        "            # label = f\"class name = {class_name}, class id = {class_id + 1}, confidence = {confidence:.2f}\"\n",
        "            # print(label)\n",
        "            # detected_objects_in_frame.append(label)\n",
        "            detections.add(class_name)\n",
        "      # print(\"     Frame : \", idx, \", Detections : \", detections)\n",
        "      for item in detections:\n",
        "        all_detections.add(item)\n",
        "  print(\"Segment detections : \", all_detections)\n",
        "  return all_detections"
      ],
      "metadata": {
        "id": "G73-rB6q24K4"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 15. Run inference for object detection\n",
        "for video in object_videos_segments:\n",
        "  url = video[0]\n",
        "  video_segments = video[1]\n",
        "  video_segments_playable = video[2]\n",
        "\n",
        "  object_segments_detection[url].clear()\n",
        "\n",
        "  print(\"Url : \", url)\n",
        "  print(\".............................\")\n",
        "\n",
        "  segment_id = 0\n",
        "  for segment in video_segments:\n",
        "    segment_start_time = segment_id * seconds_per_segments\n",
        "    segment_end_time = (segment_id + 1) * seconds_per_segments\n",
        "    print(\"Segment : \", segment_id+1, \" , start : \", segment_start_time, \" , end : \", segment_end_time)\n",
        "    detections = detectObjects(segment_id, video_segments[segment_id])\n",
        "    object_segments_detection[url].append(detections)\n",
        "    # media.show_video(video_segments_playable[segment_id], fps=video_fps)\n",
        "    segment_id = segment_id + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFD6ZIG2lRo",
        "outputId": "0bef55fe-a410-454b-ba75-5ec9f2ca5651"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Url :  output_videos/video1.avi\n",
            ".............................\n",
            "Segment :  1  , start :  0  , end :  5\n",
            "Segment detections :  {'car', 'person'}\n",
            "Segment :  2  , start :  5  , end :  10\n",
            "Segment detections :  {'person'}\n",
            "Segment :  3  , start :  10  , end :  15\n",
            "Segment detections :  {'car', 'person'}\n",
            "Segment :  4  , start :  15  , end :  20\n",
            "Segment detections :  {'person'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 16. Collect everything together\n",
        "individual_segment_wise_detections = []\n",
        "video_segment_detections = {}\n",
        "\n",
        "for url, video in action_videos:\n",
        "  video_segment_detections[url] = []\n",
        "\n",
        "for url, detections in video_segments_detection.items():\n",
        "  individual_segment_wise_detections.clear()\n",
        "  for i in range(0, len(detections)):\n",
        "    if detections[i] != \"nothing\":\n",
        "      individual_segment_wise_detections.append({detections[i]})\n",
        "    else:\n",
        "      individual_segment_wise_detections.append(set())\n",
        "    for item in object_segments_detection[url]:\n",
        "      for setItem in item:\n",
        "        individual_segment_wise_detections[i].add(setItem)\n",
        "    video_segment_detections[url] = individual_segment_wise_detections\n",
        "\n",
        "print(\"Videos detections : \")\n",
        "print(video_segment_detections)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmjgxYYY46ia",
        "outputId": "7e240119-60b4-4163-f6db-17794da6331a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Videos detections : \n",
            "{'output_videos/video1.avi': [{'salsa dancing', 'car', 'person'}, {'salsa dancing', 'car', 'person'}, {'car', 'person'}, {'car', 'person'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 17. Demonstration by video\n",
        "search = \"dancing\" # @param {type:\"string\"}\n",
        "search_term = search.lower()\n",
        "\n",
        "if search_term != \"\":\n",
        "  found_videos = []\n",
        "  for url, detections in video_segment_detections.items():\n",
        "    for segment in detections:\n",
        "      for item in segment:\n",
        "        if search_term in item:\n",
        "          found_videos.append(url)\n",
        "          break\n",
        "      else:\n",
        "        continue\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "    break\n",
        "  for url, video in object_videos:\n",
        "    for item in found_videos:\n",
        "      if url == item:\n",
        "        media.show_video(video, fps=video_fps)\n",
        "        break"
      ],
      "metadata": {
        "id": "5lVkIJyr4-HW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}